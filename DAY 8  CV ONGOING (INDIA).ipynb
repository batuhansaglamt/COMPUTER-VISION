{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b728bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1720541861.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/_k/_h4vm2qn2cqgtgmmlj65k5vc0000gn/T/ipykernel_9299/1720541861.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    def face_detector(img, size=0.5)\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_classifier = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "def face_detector(img, size=0.5)\n",
    "\n",
    "\n",
    "gray= cv2.cvt.Color(img,cv2,COLOUR_BGR2GRAY)\n",
    "faces= face_classifier.detectMultiscale(gray, 1.3,5)\n",
    "if faces is():\n",
    "    return img\n",
    "for (x,y,w,h) in faces;\n",
    "\n",
    "x= x-50\n",
    "y= y+ 50\n",
    "w= w-50\n",
    "h=h + 50\n",
    "\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "roi_gray = gray[y:y+h, x: x+w]\n",
    "roi_color = img[y:y+h, x: x+w]\n",
    " eyes= eye_classifier.detectMultiScale(roi_gray)\n",
    "    sleep(.05)\n",
    "\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "        \n",
    "img = cv2.flip(img,1)\n",
    "return img \n",
    "\n",
    "cap=cv2.VideoCapture()\n",
    "\n",
    "while True:\n",
    "    ret, frame =cap.read()\n",
    "\n",
    "cv2.imshow(\"Our face extractor\", face_detector(frame))\n",
    "\n",
    "if cv2.waitKey(1) == 13:\n",
    "    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_classifier = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) == 0:\n",
    "        return img\n",
    "    for (x, y, w, h) in faces:\n",
    "        x = x - 50\n",
    "        y = y + 50\n",
    "        w = w - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        sleep(0.05)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 0, 255), 2)\n",
    "    img = cv2.flip(img, 1)\n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Our face extractor\", face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af23e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY 8  CV ONGOING (INDIA).ipynb      cars.mp4.zip\r\n",
      "DAY 8 COMP VISION (INDIA).ipynb      day8.ipynb\r\n",
      "IMG_1063.MOV                         gradient.jpg\r\n",
      "LECTURE 8 OPEN CV -SON.ipynb         gradient.jpg.zip\r\n",
      "LECTURE 8 OPEN CV.ipynb              haarcascade_frontalface_default.xml\r\n",
      "Origin_of_Species.jpg                input.jpg\r\n",
      "Origin_of_Species.jpg.zip            input.jpg.zip\r\n",
      "Waldo.jpg                            input34.jpg\r\n",
      "WaldoBeach.jpg                       opencv.jpeg\r\n",
      "airplanes.mp4                        opencv_inv.png\r\n",
      "benvearki.jpeg                       opencv_inv.png.zip\r\n",
      "box_in_scene.png                     output.png\r\n",
      "bunchofshapes.jpg                    output.png.zip\r\n",
      "cars 2.mp4                           oxford.jpg\r\n",
      "cars.mp4                             oxford.jpg.zip\r\n",
      "cars.mp4 (1).zip                     sunflowers.jpg\r\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "from time import sleep\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMuktiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face=img[y:t+h,x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "cap= cv2.VideoCapture(0)\n",
    "count= 0\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count +=1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        file_name_path = \"./faces/user\" + str(count)+ \"jpg\"\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        cv2.puttext(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0))\n",
    "        cv2.imshow(\"Face Cropper\",face)\n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "        if cv2.waitKey(1)== or count==100:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1158e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from time import sleep\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path = \"./faces/user\" + str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0))\n",
    "        cv2.imshow(\"Face Cropper\", face)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q') or count == 100:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b76265",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_k/_h4vm2qn2cqgtgmmlj65k5vc0000gn/T/ipykernel_11188/1006795870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mLabels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTraining_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabesls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir \n",
    "from os.path import isfile,join\n",
    "\n",
    "data_path =\"./faces/user\"\n",
    "onlyfiles =[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data,Labels = [],[]\n",
    "\n",
    "for  i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images =cv2.imread(image_path,cv2,IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images,dtype = np.uint8))\n",
    "    Labels.append(i)\n",
    "    \n",
    "Labels =np.asarray(Labels,dtype=np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data),np.asarray(Labesls))\n",
    "print(\"model trained succesfully\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773ceb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.7.0.72-cp37-abi3-macosx_10_16_x86_64.whl (63.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 MB\u001b[0m \u001b[31m641.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/batuhansaglam/opt/anaconda3/lib/python3.9/site-packages (from opencv-contrib-python) (1.22.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.7.0.72\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a5a537",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_k/_h4vm2qn2cqgtgmmlj65k5vc0000gn/T/ipykernel_11188/3752672779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./faces/user\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0monlyfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "data_path = \"./faces/user\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "face_encodings = []\n",
    "labels = []\n",
    "\n",
    "for file in onlyfiles:\n",
    "    image_path = join(data_path, file)\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    encoding = face_recognition.face_encodings(image)[0]\n",
    "    face_encodings.append(encoding)\n",
    "    labels.append(file.split(\".\")[0])\n",
    "\n",
    "face_encodings = np.asarray(face_encodings)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "# Save the face encodings and labels for later use\n",
    "np.save(\"face_encodings.npy\", face_encodings)\n",
    "np.save(\"labels.npy\", labels)\n",
    "\n",
    "print(\"Model trained successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f121e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f8e377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b9337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52c5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca7741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599c80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e116b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a885655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482f2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204f954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78983aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e7d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d337e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f42142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6439b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e1c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0357572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03b615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1ca9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc53102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4d108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5c6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ad949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d53c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb589de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf3497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd34f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954dc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a6ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
